{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KTP terlah direname sesuai dengan format: nama_orang.jpg\n",
    "filenames = os.listdir('dataset/ktp/')\n",
    "path = []\n",
    "filename_no_ext = []\n",
    "for i in filenames:\n",
    "    path.append('dataset/ktp/'+i)\n",
    "    filename_no_ext.append(i.split('.')[0])\n",
    "\n",
    "# read image\n",
    "\n",
    "img = []\n",
    "for i in path:\n",
    "    img.append(cv2.imread(i))\n",
    "\n",
    "# tampilkan 10 gambar pertama\n",
    "plt.subplots(figsize=(15, 15))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(5, 2, i+1)\n",
    "    plt.imshow(cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(filename_no_ext[i])\n",
    "    plt.axis('off')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pake yolo v8 buat deteksi objek (disini kasusnya foto dalam ktp) im speeed kcchaw\n",
    "\n",
    "#model pretrained dari ultralytics menggunakan dataset COCO8\n",
    "\n",
    "# names:\n",
    "#   0: person\n",
    "#   1: bicycle\n",
    "#   2: car\n",
    "#   3: motorcycle\n",
    "#   4: airplane\n",
    "#   5: bus\n",
    "#   6: train\n",
    "#   7: truck\n",
    "#   8: boat\n",
    "#   9: traffic light\n",
    "#   10: fire hydrant\n",
    "#   11: stop sign\n",
    "#   12: parking meter\n",
    "#   13: bench\n",
    "#   14: bird\n",
    "#   15: cat\n",
    "#   16: dog\n",
    "#   17: horse\n",
    "#   18: sheep\n",
    "#   19: cow\n",
    "#   20: elephant\n",
    "#   21: bear\n",
    "#   22: zebra\n",
    "#   23: giraffe\n",
    "#   24: backpack\n",
    "#   25: umbrella\n",
    "#   26: handbag\n",
    "#   27: tie\n",
    "#   28: suitcase\n",
    "#   29: frisbee\n",
    "#   30: skis\n",
    "#   31: snowboard\n",
    "#   32: sports ball\n",
    "#   33: kite\n",
    "#   34: baseball bat\n",
    "#   35: baseball glove\n",
    "#   36: skateboard\n",
    "#   37: surfboard\n",
    "#   38: tennis racket\n",
    "#   39: bottle\n",
    "#   40: wine glass\n",
    "#   41: cup\n",
    "#   42: fork\n",
    "#   43: knife\n",
    "#   44: spoon\n",
    "#   45: bowl\n",
    "#   46: banana\n",
    "#   47: apple\n",
    "#   48: sandwich\n",
    "#   49: orange\n",
    "#   50: broccoli\n",
    "#   51: carrot\n",
    "#   52: hot dog\n",
    "#   53: pizza\n",
    "#   54: donut\n",
    "#   55: cake\n",
    "#   56: chair\n",
    "#   57: couch\n",
    "#   58: potted plant\n",
    "#   59: bed\n",
    "#   60: dining table\n",
    "#   61: toilet\n",
    "#   62: tv\n",
    "#   63: laptop\n",
    "#   64: mouse\n",
    "#   65: remote\n",
    "#   66: keyboard\n",
    "#   67: cell phone\n",
    "#   68: microwave\n",
    "#   69: oven\n",
    "#   70: toaster\n",
    "#   71: sink\n",
    "#   72: refrigerator\n",
    "#   73: book\n",
    "#   74: clock\n",
    "#   75: vase\n",
    "#   76: scissors\n",
    "#   77: teddy bear\n",
    "#   78: hair drier\n",
    "#   79: toothbrush\n",
    "\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 10.5ms\n",
      "Speed: 9.8ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 416x640 1 person, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9.2ms\n",
      "Speed: 1.9ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 person, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 416x640 1 person, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 2 persons, 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 1 person, 9.7ms\n",
      "Speed: 2.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 1 person, 8.9ms\n",
      "Speed: 1.8ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 448x640 1 person, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 416x640 1 person, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 448x640 1 person, 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 416x640 1 person, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 1 person, 9.2ms\n",
      "Speed: 1.8ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 1 person, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 416x640 1 person, 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    }
   ],
   "source": [
    "#lakukan cropping pada setiap hasil deteksi class 0 (person)\n",
    "for i in range(len(img)):\n",
    "    # konfigurasi model agar hanya mendeteksi class 0 (person)\n",
    "    result = model.predict(img[i], classes=0)\n",
    "    for r in result:\n",
    "        annotator = Annotator(img[i])\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            b = box.xyxy[0]\n",
    "            c = box.cls\n",
    "            # crop image n save ke folder ktp/faces\n",
    "            crop_img = img[i][int(b[1]):int(b[3]), int(b[0]):int(b[2])]\n",
    "            cv2.imwrite('dataset/faces/'+filename_no_ext[i]+'.jpg', crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir('dataset/faces/')\n",
    "path = []\n",
    "filename_no_ext = []\n",
    "for i in filenames:\n",
    "    path.append('dataset/faces/'+i)\n",
    "    filename_no_ext.append(i.split('.')[0])\n",
    "\n",
    "# read image\n",
    "img = []\n",
    "for i in path:\n",
    "    img.append(cv2.imread(i))\n",
    "\n",
    "# tampilkan 10 gambar pertama\n",
    "plt.subplots(figsize=(15, 15))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(5, 2, i+1)\n",
    "    plt.imshow(cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(filename_no_ext[i])\n",
    "    plt.axis('off')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
